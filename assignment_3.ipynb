{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6c1330",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "### Due Tuesday 9/23. Do four of five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46869e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7761202",
   "metadata": {},
   "source": [
    "1. \n",
    "- Open the NHANES (or Ames prices or college completion datasets, if you prefer)\n",
    "- Find two categorical variables of interest (there are 198, and short descriptions are given in the `nhanes_meta_17_18.csv` file). Investigate their missing values (you don't have to focus on missing values for this analysis like we did with police use of force, but always be aware of how dirty the data are)\n",
    "- Compute a contingency table for your categorical $X$ and $Y$\n",
    "- Discuss any interesting patterns (or lack of one) that you observe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa843c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crush\\AppData\\Local\\Temp\\ipykernel_31704\\3076742054.py:1: DtypeWarning: Columns (142) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(r\"C:\\Users\\crush\\OneDrive\\Desktop\\DS 5030\\understanding_uncertainty\\data\\nhanes_data_17_18.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\crush\\OneDrive\\Desktop\\DS 5030\\understanding_uncertainty\\data\\nhanes_data_17_18.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e956e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values for Diet: 2540\n",
      "Missing Values for Milk: 1\n"
     ]
    }
   ],
   "source": [
    "# investigate missing values\n",
    "print(f\"Missing Values for Diet: {data['HowHealthyIsTheDiet'].isna().sum()}\")\n",
    "print(f\"Missing Values for Milk: {data['Past30DayMilkProductConsumption'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4065997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>HowHealthyIsTheDiet</th>\n",
       "      <th>Excellent</th>\n",
       "      <th>Fair</th>\n",
       "      <th>Good</th>\n",
       "      <th>Poor</th>\n",
       "      <th>Very good</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Past30DayMilkProductConsumption</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Never</th>\n",
       "      <td>0.086739</td>\n",
       "      <td>0.256047</td>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.078399</td>\n",
       "      <td>0.202669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Often-once a day or more?</th>\n",
       "      <td>0.093381</td>\n",
       "      <td>0.243499</td>\n",
       "      <td>0.389480</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.213357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rarely-less than once a week</th>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.290894</td>\n",
       "      <td>0.394037</td>\n",
       "      <td>0.078163</td>\n",
       "      <td>0.182111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sometimes-once a week or more but less than once a day or</th>\n",
       "      <td>0.064555</td>\n",
       "      <td>0.277944</td>\n",
       "      <td>0.403467</td>\n",
       "      <td>0.059773</td>\n",
       "      <td>0.194262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Varied</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "HowHealthyIsTheDiet                                 Excellent      Fair  \\\n",
       "Past30DayMilkProductConsumption                                           \n",
       "Never                                                0.086739  0.256047   \n",
       "Often-once a day or more?                            0.093381  0.243499   \n",
       "Rarely-less than once a week                         0.054795  0.290894   \n",
       "Sometimes-once a week or more but less than onc...   0.064555  0.277944   \n",
       "Varied                                               0.047619  0.333333   \n",
       "\n",
       "HowHealthyIsTheDiet                                     Good      Poor  \\\n",
       "Past30DayMilkProductConsumption                                          \n",
       "Never                                               0.376147  0.078399   \n",
       "Often-once a day or more?                           0.389480  0.060284   \n",
       "Rarely-less than once a week                        0.394037  0.078163   \n",
       "Sometimes-once a week or more but less than onc...  0.403467  0.059773   \n",
       "Varied                                              0.428571  0.095238   \n",
       "\n",
       "HowHealthyIsTheDiet                                 Very good  \n",
       "Past30DayMilkProductConsumption                                \n",
       "Never                                                0.202669  \n",
       "Often-once a day or more?                            0.213357  \n",
       "Rarely-less than once a week                         0.182111  \n",
       "Sometimes-once a week or more but less than onc...   0.194262  \n",
       "Varied                                               0.095238  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contingency table from notes\n",
    "pd.crosstab(data['Past30DayMilkProductConsumption'], data['HowHealthyIsTheDiet'],normalize='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3695b6",
   "metadata": {},
   "source": [
    "**Patterns:** According to this contingency table, a \"Good\" diet seems to be the most common observation no matter the milk consumption over the past 30 days. Moreover, a \"Fair\" diet is in second place no matter the milk consumption habits of the respondent. One thing that deviates from a pattern is the percentage of observations that have both \"Varied\" milk consumption and a \"Very Good\" diet. Generally, no matter the milk consumption, the fraction of onbservations also having a \"Very Good\" diet is approxiamtely 1 in 5. However, for \"Varied\" milk consumption, the proportion of \"Very Good\" diets is half of that, at 10%. There also seems to be a trend that for respondents with \"Varied\" milk consumption, they tend to rate their diet more negatively with the \"Varied\" category being the highest in \"Poor\" at 9.5% and lowest in \"Excellent\" and \"Very Good\" at 4.7% and 9.5%, respectively. Most importantly, there doesn't seem to be any difference in the respondent's diet when their milk consumption is \"Often\" or \"Never.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cef48e5",
   "metadata": {},
   "source": [
    "2. \n",
    "- Open the NHANES dataset\n",
    "- Find a categorical and numeric variable of interest (there are 198, and short descriptions are given in the `nhanes_meta_17_18.csv` file). Investigate their missing values (you don't have to focus on missing values for this analysis, but always be aware of them)\n",
    "- Make descriptive tables and grouped kernel density plots to represent the variation in your numeric $Y$ conditional on your categorical $X$\n",
    "- Discuss any interesting patterns (or lack of one) that you observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4952e789",
   "metadata": {},
   "source": [
    "3. \n",
    "We showed that the mean and median could be discovered by minimizing various kinds of loss functions; this is what machine learning is. To make a prediction $\\hat{y}(z)$ of $Y$ when $X=z$, minimize the mean squared error:\n",
    "$$\n",
    "MSE(\\hat{y}(z)) = \\dfrac{1}{N} \\sum_{i=1}^N \\left\\lbrace y_i - \\hat{y}(z) \\right\\rbrace^2 \\frac{1}{h}k\\left(\\frac{z-x_i}{h}\\right)\n",
    "$$\n",
    "Show that the solution to this problem is the LCLS/Naradaya-Watson estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98884d76",
   "metadata": {},
   "source": [
    "4. \n",
    "- Write a class or set of functions that implement the LCLS/Naradaya-Watson estimator, using the Silverman plug-in estimate for the conditioning variable $X$ as the bandwidth.\n",
    "- From one of the course data sets, find two numeric variables of interest, analyze their relationship with the the LCLS/Naradaya-Watson estimator, and discuss your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0534c110",
   "metadata": {},
   "source": [
    "5. \n",
    "- In any of the available data sets, investigate the relationships between pairs of variables $(X,Y)$ with a scatterplot and CEF (for example, price on area)\n",
    "- Is this relationship plausibly causal, or are there missing variables that might explain at least part of the relationship between your variables? These can be \"conceptual\" rather than \"practical\"; for example, 'talent' or 'grit' probably explain education outcomes, but are almost impossible to measure. We are asking whether there are hypothetical **threats to causal identification** of the effect of $X$ on $Y$.\n",
    "- Explain how, regardless of the threat to causal identification, you can still use your model to predict $Y$ given $X$, as long as you don't intervene in the system to control the outcome"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
